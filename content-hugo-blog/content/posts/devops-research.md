+++
date = "2016-11-17T15:10:33Z"
draft = true
title = "DevOps tools applied in Academic Research"

+++

### From the memoir: 
While in college, in the 90's, I was learning all sort of cool stuff among it C and C++. But in my research internships the standard used language was Fortran, and there was a reticence to rewrite code in the newer, cool languages...In graduate school things were not that different. Some students we got together to form a support group to change the status quo and use new tools.


Computational task in research can be roughly divided in two kinds:

* Analysing data 

* Generating data 

** Analysing Data ** is devoted to gather useful information from raw experimental data. Some experiments can produce massive amount of data that the only possible way to find correlations or any meaningful information is through intensive computing processing that in may cases involve sophisticated algorithms. The computational requirements to run these tasks are expensive and some times a super computer is the only viable way to produce an analysis in a decent amount of time.

Many areas of research perform this kind of analysis such as astrophysic, material science, fluid mechanics, particle physics. However the most prominent areas that have found a market fall in the biomedical in biotechnologial research. In recent years there has been an increase in the number of start-ups using cloud services for compute intensive analysis such as DNAnexus, Genome Compiler, MetaMixis and Recursion Pharma among others. All devoted in the finding correlations between existing data in order to find markers for pathologies, facilitate protein engineering or facilitate drug discovery.

